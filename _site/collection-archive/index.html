

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Posts by Collection - chrisâ€™s website</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="chris's website">
<meta property="og:title" content="Posts by Collection">


  <link rel="canonical" href="http://localhost:4000/collection-archive/">
  <meta property="og:url" content="http://localhost:4000/collection-archive/">







  

  












  <script type="application/ld+json">
    {
      "@context" : "http://schema.org",
      "@type" : "Person",
      "name" : "chen yongbiao",
      "url" : "http://localhost:4000",
      "sameAs" : null
    }
  </script>






<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="chris's website Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<link rel="apple-touch-icon" sizes="57x57" href="http://localhost:4000/images/apple-touch-icon-57x57.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="60x60" href="http://localhost:4000/images/apple-touch-icon-60x60.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="76x76" href="http://localhost:4000/images/apple-touch-icon-76x76.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="120x120" href="http://localhost:4000/images/apple-touch-icon-120x120.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="152x152" href="http://localhost:4000/images/apple-touch-icon-152x152.png?v=M44lzPylqQ">
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:4000/images/apple-touch-icon-180x180.png?v=M44lzPylqQ">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32">
<link rel="icon" type="image/png" href="http://localhost:4000/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96">
<link rel="icon" type="image/png" href="http://localhost:4000/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16">
<link rel="manifest" href="http://localhost:4000/images/manifest.json?v=M44lzPylqQ">
<link rel="mask-icon" href="http://localhost:4000/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000">
<link rel="shortcut icon" href="/images/favicon.ico?v=M44lzPylqQ">
<meta name="msapplication-TileColor" content="#000000">
<meta name="msapplication-TileImage" content="http://localhost:4000/images/mstile-144x144.png?v=M44lzPylqQ">
<meta name="msapplication-config" content="http://localhost:4000/images/browserconfig.xml?v=M44lzPylqQ">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css"/>

<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML' async></script>

<!-- end custom head snippets -->

  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">chris's website</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/project/">Projects</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/year-archive/">News</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/cv/">CV</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    



<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/bio1.JPG" class="author__avatar" alt="Yongbiao Chen">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Yongbiao Chen</h3>
    <p class="author__bio">I am a phd candidate at Shanghai Jiao Tong University. </p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      
        <li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Shanghai</li>
      
      
      
      
        <li><a href="mailto:chenyongbiao0319@sjtu.edu.cn"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li>
      
      
       
        <li><a href="https://www.researchgate.net/scientific-contributions/Yongbiao-Chen-2175795039"><i class="fab fa-fw fa-researchgate" aria-hidden="true"></i> ResearchGate</a></li>
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://github.com/chrisbyd"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li>
      
      
      
      
      
      
      
      
      
      
      
      
      
      
        <li><a href="https://scholar.google.com/citations?user=ze0T10EAAAAJ&hl=en&oi=ao"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li>
      
      
        <li><a href="https://www.ncbi.nlm.nih.gov/pubmed/?term=john+snow"><i class="ai ai-pubmed-square ai-fw"></i> PubMed</a></li>
      
      
        <li><a href="https://orcid.org/0000-0002-7727-5489"><i class="ai ai-orcid-square ai-fw"></i> ORCID</a></li>
      
      
      
    </ul>
  </div>
</div>

  
  </div>


  <div class="archive">
    
      <h1 class="page__title">Posts by Collection</h1>
    
    



  
    
    
      <h2 id="portfolio" class="archive__subtitle">portfolio</h2>
      
    
  
  

  
  
    
  
    
  
    
  
    
  
    
  

  
    
    
      <h2 id="publications" class="archive__subtitle">publications</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2009-10-01-paper-title-number-1" rel="permalink">MAENet: Boosting Feature Representation for Cross-Modal Person Re-Identification with Pairwise Supervision
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Multimedia Retrieval (ICMR)</i>, 2020 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>It targets at tackling the challenging cross-modal person re-identification problem. We present a novel modality and appearance invariant embedding learning framework equipped with maximum likelihood learning to perform cross-modal person re-identification.</p>
</p>
    
    
    
      <p>Recommended citation: Chen, Y., Zhang, S. and Qi, Z., 2020, June. Maenet: Boosting feature representation for cross-modal person re-identification with pairwise supervision. In Proceedings of the 2020 International Conference on Multimedia Retrieval (pp. 442-449). <a href="http://chrisbyd.github.io/files/maenet.pdf"><u>http://chrisbyd.github.io/files/maenet.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-009" rel="permalink">Non-Local Attention Learning for Medical Image Classification
</a>
      
    </h2>
    
    

        
          <p>Published in <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>We propose a non-local attention learning method that models long-range dependencies between pixels to preserve global information and help CNNs better identify the tiny lesions.</p>
</p>
    
    
    
      <p>Recommended citation: Wen, Y., Chen, L., Chen, H., Tang, X., Deng, Y., Chen, Y. and Zhou, C., 2021, July. Non-Local Attention Learning for Medical Image Classification. In 2021 IEEE International Conference on Multimedia and Expo (ICME) (pp. 1-6). IEEE. <a href="http://chrisbyd.github.io/files/nonlocal.pdf"><u>http://chrisbyd.github.io/files/nonlocal.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-004" rel="permalink">Bit-transformer: Transforming bit-level sparsity into higher preformance in reram-based accelerator
</a>
      
    </h2>
    
    

        
          <p>Published in <i>IEEE/ACM International Conference On Computer Aided Design (ICCAD)</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>We develop a novel ReRAM-based DNN accelerator, named Bit-Transformer, which pays attention to the correlation between the bit-level sparsity and the performance of the ReRAM-based crossbar.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., He, Z., Wang, Z., Zhao, Y., Chen, Y. and Jiang, L., 2021, November. Bit-transformer: Transforming bit-level sparsity into higher preformance in reram-based accelerator. In 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD) (pp. 1-9). IEEE. <a href="http://chrisbyd.github.io/files/bitrans.pdf"><u>http://chrisbyd.github.io/files/bitrans.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-008" rel="permalink">Seq-Masks: Bridging the gap between appearance and gait modeling for video-based person re-identification
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Visual Communications and Image Processing (VCIP)</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>We propose a framework that utilizes the sequence masks (SeqMasks) in the video to integrate appearance information and gait modeling in a close fashion.</p>
</p>
    
    
    
      <p>Recommended citation: Chang, Z., Yang, Z., Chen, Y., Zhou, Q. and Zheng, S., 2021, December. Seq-Masks: Bridging the gap between appearance and gait modeling for video-based person re-identification. In 2021 International Conference on Visual Communications and Image Processing (VCIP) (pp. 1-5). IEEE. <a href="http://chrisbyd.github.io/files/seqmask.pdf"><u>http://chrisbyd.github.io/files/seqmask.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-002" rel="permalink">Sstdp: Supervised spike timing dependent plasticity for efficient spiking neural network training
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Frontiers in Neuroscience</i>, 2021 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper addresses the training problem for spiking neural network. It introduces a new learning algorithm, called SSTDP, to train snn efficiently</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Chen, Y., Wang, Z., Yang, T. and Jiang, L., 2021. Sstdp: Supervised spike timing dependent plasticity for efficient spiking neural network training. Frontiers in Neuroscience, 15. <a href="http://chrisbyd.github.io/files/SSTDP.pdf"><u>http://chrisbyd.github.io/files/SSTDP.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-012" rel="permalink">DSPR: Secure decentralized storage with proof-of-replication for edge devices
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Journal of Systems Architecture</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper presents DSPR, a new decentralized distributed storage system with proof of replication for edge and IoT devices.</p>
</p>
    
    
    
      <p>Recommended citation: Wu, C., Chen, Y., Qi, Z. and Guan, H., 2022. DSPR: Secure decentralized storage with proof-of-replication for edge devices. Journal of Systems Architecture, 125, p.102441 <a href="http://chrisbyd.github.io/files/DSPR.pdf"><u>http://chrisbyd.github.io/files/DSPR.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-010" rel="permalink">DynSNN: A Dynamic Approach to Reduce Redundancy in Spiking Neural Networks
</a>
      
    </h2>
    
    

        
          <p>Published in <i>IEEE International Conference on Multimedia and Expo (ICME)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>In this paper, inspired by the topology of neuronal co-activity in the neural system, we propose a dynamic pruning framework (dubbed DynSNN) for SNNs, enabling us to seamlessly optimize network topology on the ï¬‚y almost without accuracy loss.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Chen, Y., Wang, Z. and Dai, F., 2022, May. DynSNN: A Dynamic Approach to Reduce Redundancy in Spiking Neural Networks. In ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) (pp. 2130-2134). IEEE. <a href="http://chrisbyd.github.io/files/dynsnn.pdf"><u>http://chrisbyd.github.io/files/dynsnn.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-003" rel="permalink">Spikeconverter: An efficient conversion framework zipping the gap between artificial neural networks and spiking neural networks
</a>
      
    </h2>
    
    

        
          <p>Published in <i>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes  a conversion framework to mitigate the gap between the activation value of source ANN and the generated spike train of target SNN.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Chen, Y., Wang, Z. and Jiang, L., 2022. Spikeconverter: An efficient conversion framework zipping the gap between artificial neural networks and spiking neural networks. In Proceedings of the AAAI Conference on Artificial Intelligence. <a href="http://chrisbyd.github.io/files/spikeConverter.pdf"><u>http://chrisbyd.github.io/files/spikeConverter.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2010-10-01-paper-title-number-2" rel="permalink">Transhash: Transformer-based hamming hashing for efficient image retrieval
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Multimedia Retrieval (ICMR)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>It proposes the first vision transformer based deep hashing framework for large-scale image retrieval.</p>
</p>
    
    
    
      <p>Recommended citation: Chen, Y., Zhang, S., Liu, F., Chang, Z., Ye, M. and Qi, Z., 2022, June. Transhash: Transformer-based hamming hashing for efficient image retrieval. In Proceedings of the 2022 International Conference on Multimedia Retrieval (pp. 127-136). <a href="http://chrisbyd.github.io/files/TransHash.pdf"><u>http://chrisbyd.github.io/files/TransHash.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2015-10-01-paper-title-number-3" rel="permalink">Supervised Contrastive Vehicle Quantization for Efficient Vehicle Retrieval
</a>
      
    </h2>
    
    

        
          <p>Published in <i>International Conference on Multimedia Retrieval (ICMR)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes a product quantization framework for efficient large-scale vehicle re-identification</p>
</p>
    
    
    
      <p>Recommended citation: Chen, Y., Guo, K., Liu, F., Huang, Y. and Qi, Z., 2022, June. Supervised Contrastive Vehicle Quantization for Efficient Vehicle Retrieval. In Proceedings of the 2022 International Conference on Multimedia Retrieval (pp. 44-48). <a href="http://chrisbyd.github.io/files/SCVQ.pdf"><u>http://chrisbyd.github.io/files/SCVQ.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-001" rel="permalink">DVHN: A Deep Hashing Framework for Large-scale Vehicle Re-identification
</a>
      
    </h2>
    
    

        
          <p>Published in <i>(To appear) IEEE Transactions on Intelligent Transportation</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes the first deep hashing based vehicle re-identification framework for efficient large-scale vehicle re-identification</p>
</p>
    
    
    
      <p>Recommended citation: Chen, Y., Zhang, S., Liu, F., Wu, C., Guo, K. and Qi, Z., 2021. DVHN: A Deep Hashing Framework for Large-scale Vehicle Re-identification. arXiv preprint arXiv:2112.04937. <a href="http://chrisbyd.github.io/files/DVHN.pdf"><u>http://chrisbyd.github.io/files/DVHN.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-005" rel="permalink">SATO: spiking neural network acceleration via temporal-oriented dataflow and architecture
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM/IEEE Design Automation Conference (DAC)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes SATO, a temporal-parallel SNN accelerator that accumulates the membrane potential for all time steps in parallel.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Wang, Z., Chen, Y., Yang, T., He, Z., Yang, X. and Jiang, L., 2022, July. SATO: spiking neural network acceleration via temporal-oriented dataflow and architecture. In Proceedings of the 59th ACM/IEEE Design Automation Conference (pp. 1105-1110). <a href="http://chrisbyd.github.io/files/SATO.pdf"><u>http://chrisbyd.github.io/files/SATO.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-006" rel="permalink">PIM-DH: ReRAM-based processing-in-memory architecture for deep hashing acceleration
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM/IEEE Design Automation Conference (DAC)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes the first PIM-based scheme for deep hashing accelerator, namely PIM-DH.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Chen, Y., Wang, Z., He, Z., Yang, R., Tang, Q., Yang, T., Zhuo, C. and Jiang, L., 2022, July. PIM-DH: ReRAM-based processing-in-memory architecture for deep hashing acceleration. In Proceedings of the 59th ACM/IEEE Design Automation Conference (pp. 1087-1092). <a href="http://chrisbyd.github.io/files/PIM-DH.pdf"><u>http://chrisbyd.github.io/files/PIM-DH.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-007" rel="permalink">EBSP: evolving bit sparsity patterns for hardware-friendly inference of quantized deep neural networks.
</a>
      
    </h2>
    
    

        
          <p>Published in <i>ACM/IEEE Design Automation Conference (DAC)</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This paper proposes the integration of aggressive joint-way compression into hardware design, namely EBSP.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Zhao, W., Wang, Z., Chen, Y., He, Z., Jing, N., Liang, X. and Jiang, L., 2022, July. EBSP: evolving bit sparsity patterns for hardware-friendly inference of quantized deep neural networks. In Proceedings of the 59th ACM/IEEE Design Automation Conference (pp. 259-264). <a href="http://chrisbyd.github.io/files/EBSP.pdf"><u>http://chrisbyd.github.io/files/EBSP.pdf</u></a></p>
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/publication/2022-011" rel="permalink">SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator
</a>
      
    </h2>
    
    

        
          <p>Published in <i>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems.</i>, 2022 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>We develop a novel ReRAM-based DNN accelerator, named Sparse-Multiplication-Engine (SME), based on a hardware and software co-design framework.</p>
</p>
    
    
    
      <p>Recommended citation: Liu, F., Wang, Z., Chen, Y., He, Z., Yang, T., Liang, X. and Jiang, L., 2022. SoBS-X: Squeeze-Out Bit Sparsity for ReRAM-Crossbar-Based Neural Network Accelerator. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. <a href="http://chrisbyd.github.io/files/SoBS-X.pdf"><u>http://chrisbyd.github.io/files/SoBS-X.pdf</u></a></p>
    

  </article>
</div>

    
  

  
    
    
      <h2 id="talks" class="archive__subtitle">talks</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2012-03-01-talk-1" rel="permalink">Talk 1 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2012-03-01T00:00:00-08:00">March 01, 2012</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of your talk, which is a markdown files that can be all markdown-ified like any other post. Yay markdown!</p>
</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2013-03-01-tutorial-1" rel="permalink">Tutorial 1 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2013-03-01T00:00:00-08:00">March 01, 2013</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p><a href="http://exampleurl.com">More information here</a></p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2014-02-01-talk-2" rel="permalink">Talk 2 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-02-01T00:00:00-08:00">February 01, 2014</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p><a href="http://example2.com">More information here</a></p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/talks/2014-03-01-talk-3" rel="permalink">Conference Proceeding talk 3 on Relevant Topic in Your Field
</a>
      
    </h2>
    
    

        
         <p class="page__date"><strong><i class="fa fa-fw fa-calendar" aria-hidden="true"></i> Published:</strong> <time datetime="2014-03-01T00:00:00-08:00">March 01, 2014</time></p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of your conference proceedings talk, note the different field in type. You can put anything in this field.</p>
</p>
    
    
    

  </article>
</div>

    
  

  
    
    
      <h2 id="teaching" class="archive__subtitle">teaching</h2>
      
    
  
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/teaching/2014-spring-teaching-1" rel="permalink">Teaching experience 1
</a>
      
    </h2>
    
    

        
          <p> Undergraduate course, <i>University 1, Department</i>, 2014 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of a teaching experience. You can use markdown like any other post.</p>

</p>
    
    
    

  </article>
</div>

    
  
    
      





<div class="list__item">
  <article class="archive__item" itemscope itemtype="http://schema.org/CreativeWork">
    

    <h2 class="archive__item-title" itemprop="headline">
      
        <a href="http://localhost:4000/teaching/2015-spring-teaching-1" rel="permalink">Teaching experience 2
</a>
      
    </h2>
    
    

        
          <p> Workshop, <i>University 1, Department</i>, 2015 </p>
        

    
    <p class="archive__item-excerpt" itemprop="description"><p>This is a description of a teaching experience. You can use markdown like any other post.</p>

</p>
    
    
    

  </article>
</div>

    
  

  </div>
</div>


    <div class="page__footer">
      <footer>
        <!-- start custom footer snippets -->
<a href="/sitemap/">Sitemap</a>
<!-- end custom footer snippets -->

        

<div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    
    
    
    
      <li><a href="http://github.com/chrisbyd"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>
    
    
    <li><a href="http://localhost:4000/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2022 chen yongbiao. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>




  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', '', 'auto');
  ga('send', 'pageview');
</script>






  </body>
</html>

